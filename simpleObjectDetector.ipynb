{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8kJo6/D00eJi68OWLGLvh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akahaybasutkar/Object_Detector/blob/main/simpleObjectDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the libraries"
      ],
      "metadata": {
        "id": "1sQkFE3Bh45T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8pGtZqeduoD",
        "outputId": "4f8d1335-a525-4652-a39e-805fcfb1ce2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries and the methods"
      ],
      "metadata": {
        "id": "z9Gwb3ERh_me"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9671sJe0rp81"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.imagenet_utils import preprocess_input, decode_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Object Detector"
      ],
      "metadata": {
        "id": "hScK8H1biEB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectDetector:\n",
        "    def __init__(self):\n",
        "        self.image_name = None\n",
        "        self.model = None\n",
        "\n",
        "    def load_model(self, user_model=None):\n",
        "        \"\"\"\n",
        "        This is function to load the model, this may be any model that the user\n",
        "        wants to use(Prebuilt or Custom)\n",
        "\n",
        "        Parameters:\n",
        "            model (object): The actual model\n",
        "        \"\"\"\n",
        "\n",
        "        if user_model == None:\n",
        "            self.model = VGG16(weights='imagenet', include_top=True)\n",
        "            print(\"Model created\")\n",
        "        else:\n",
        "            self.model = user_model\n",
        "\n",
        "    def load_image(self, image_path):\n",
        "        \"\"\"Loads and resizes an image from the specified path.\n",
        "\n",
        "        This function reads an image from the given file path, resizes it to 672x672 pixels using Lanczos resampling,\n",
        "        and converts it to a NumPy array.\n",
        "\n",
        "        Args:\n",
        "            image_path (str): The path to the image file.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: The resized image as a NumPy array.\n",
        "\n",
        "        Raises:\n",
        "            FileNotFoundError: If the image file does not exist at the specified path.\n",
        "            cv2.error: If there's an issue loading or resizing the image using OpenCV.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                raise FileNotFoundError(f\"Image not found at: {image_path}\")\n",
        "\n",
        "            img = cv2.resize(image, (672, 672), interpolation=cv2.INTER_LANCZOS4)\n",
        "            img_array = np.asarray(img)\n",
        "            return img_array\n",
        "        except FileNotFoundError as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            raise e  # Re-raise to be handled elsewhere\n",
        "        except cv2.error as e:\n",
        "            print(f\"Error loading or resizing image: {e}\")\n",
        "            raise e  # Re-raise to be handled elsewhere\n",
        "\n",
        "\n",
        "    def preprocess_image(self, image_path, for_use='predections'):\n",
        "        \"\"\"Preprocesses an image for use in a model.\n",
        "\n",
        "        This method loads an image from the given path, resizes it to 224x224 pixels using Lanczos resampling,\n",
        "        converts it to a NumPy array, and applies model-specific preprocessing.\n",
        "\n",
        "        Args:\n",
        "            image_path (str): The path to the image file.\n",
        "            for_use (str, optional): Specifies how the image will be used.\n",
        "                                    If 'predictions', it's prepared for model inference. Defaults to 'predictions'.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: The preprocessed image array, ready for use in a model.\n",
        "\n",
        "        Raises:\n",
        "        FileNotFoundError: If the image file does not exist at the specified path.\n",
        "        cv2.error: If there's an issue loading or resizing the image using OpenCV.\n",
        "        \"\"\"\n",
        "\n",
        "        if for_use == 'predections':\n",
        "            try:\n",
        "                img = cv2.imread(image_path)\n",
        "                if img is None:\n",
        "                    raise FileNotFoundError(f\"Image not found at: {image_path}\")\n",
        "                img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_LANCZOS4)\n",
        "                img_array = np.asarray(img)\n",
        "                img_array = np.expand_dims(img_array, axis=0)\n",
        "                return preprocess_input(img_array)\n",
        "\n",
        "            except FileNotFoundError as e:\n",
        "                raise e\n",
        "            except cv2.error as e:\n",
        "                raise e\n",
        "\n",
        "\n",
        "    def break_image(self, inp_image):\n",
        "        \"\"\"Breaks a large image into smaller, overlapping 224x224 windows.\n",
        "\n",
        "        This method systematically crops the input image into overlapping windows of 224x224 pixels.\n",
        "        The cropped images are saved individually and also returned as a list.\n",
        "\n",
        "        Args:\n",
        "            inp_image (np.ndarray): The input image as a NumPy array.\n",
        "\n",
        "        Returns:\n",
        "            list[np.ndarray]: A list of cropped image arrays, each of size 224x224.\n",
        "\n",
        "        Raises:\n",
        "            TypeError: If the input image is not a NumPy array.\n",
        "            ValueError: If the input image has dimensions smaller than 224x224.\n",
        "            OSError: If there's an error creating the output directory.\n",
        "            cv2.error: If there's an issue writing the cropped images.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            if not isinstance(inp_image, np.ndarray):\n",
        "                raise TypeError(\"Input image must be a NumPy array.\")\n",
        "            if inp_image.shape[0] < 224 or inp_image.shape[1] < 224:\n",
        "                raise ValueError(\"Input image dimensions must be at least 224x224.\")\n",
        "\n",
        "            img = inp_image\n",
        "\n",
        "            window_width = 224\n",
        "            window_height = 224\n",
        "            step_size = 112  # Overlap of half the window size\n",
        "            output_dir = f\"/content/{self.image_name}/\"\n",
        "\n",
        "            os.makedirs(output_dir, exist_ok=True)  # Creating the output directory if it doesn't exist\n",
        "            cropped_images = []\n",
        "\n",
        "            for y in range(0, img.shape[0] - window_height + 1, step_size):\n",
        "                for x in range(0, img.shape[1] - window_width + 1, step_size):\n",
        "                    window = img[y:y + window_height, x:x + window_width]\n",
        "                    cropped_images.append(window.copy())\n",
        "\n",
        "                    cell_index = len(cropped_images)\n",
        "                    filename = f\"/content/{self.image_name}/cropped_cell_{cell_index}.jpg\"\n",
        "                    cv2.imwrite(filename, window)\n",
        "\n",
        "            print(f\"Extracted {len(cropped_images)} windows (224*224 images).\")\n",
        "            return cropped_images\n",
        "\n",
        "        except (TypeError, ValueError) as e:\n",
        "            raise e\n",
        "        except OSError as e:\n",
        "            print(f\"Error creating output directory: {e}\")\n",
        "            raise e\n",
        "        except cv2.error as e:\n",
        "            print(f\"Error saving cropped image: {e}\")\n",
        "            raise e\n",
        "\n",
        "    def predict_objects(self):\n",
        "        \"\"\"Predicts objects in preprocessed image windows.\n",
        "\n",
        "        This method iterates over the preprocessed image windows, predicts the top object in each window\n",
        "        using the loaded model, and returns the predictions with confidence scores above a threshold.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing two dictionaries:\n",
        "                - output_dic: A dictionary mapping window names (e.g., \"window_1\") to the top prediction tuples (id, label, confidence).\n",
        "                - predictions: A list of all top prediction tuples with confidence above the threshold.\n",
        "\n",
        "        Raises:\n",
        "            FileNotFoundError: If a preprocessed image file is not found.\n",
        "            OSError: If there's an issue accessing the image directory.\n",
        "            Exception: For any other unexpected errors during prediction or decoding.\n",
        "        \"\"\"\n",
        "\n",
        "        predictions = []\n",
        "        output_dic = {}\n",
        "\n",
        "        try:\n",
        "            for i in range(1, 26):\n",
        "                current_image_path = f\"/content/{self.image_name}/cropped_cell_{i}.jpg\"\n",
        "\n",
        "                # Ensure the image file exists\n",
        "                if not os.path.exists(current_image_path):\n",
        "                    raise FileNotFoundError(f\"Image not found at: {current_image_path}\")\n",
        "\n",
        "                image = self.preprocess_image(current_image_path)\n",
        "                prediction = self.model.predict(image)\n",
        "                top_predictions = decode_predictions(prediction, top=1)[0]\n",
        "\n",
        "                for (id, label, confidence) in top_predictions:\n",
        "                    if confidence > 0.5:  # Filter for confidence above the threshold\n",
        "                        output_dic[f\"window_{i}\"] = top_predictions[0]\n",
        "                        predictions.append(top_predictions[0])\n",
        "\n",
        "            return output_dic, predictions\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            raise e\n",
        "        except OSError as e:\n",
        "            print(f\"Error accessing directory: {e}\")\n",
        "            raise e\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error during prediction: {e}\")\n",
        "            raise e\n",
        "\n",
        "\n",
        "        return output_dic, predections\n",
        "\n",
        "    def predict_image(self, image_path, img_name):\n",
        "        \"\"\"Predicts objects in an image.\n",
        "\n",
        "        This method loads an image from the given path, breaks it into smaller windows,\n",
        "        preprocesses each window, and then uses the loaded model to predict the objects\n",
        "        in each window. It returns the predictions for each window.\n",
        "\n",
        "        Args:\n",
        "            image_path (str): The path to the image file.\n",
        "            img_name (str): The name to be used for saving the image.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing two dictionaries:\n",
        "                - output_dic: A dictionary mapping window names (e.g., \"window_1\") to the top prediction tuples (id, label, confidence).\n",
        "                - predictions: A list of all top prediction tuples with confidence above the threshold.\n",
        "\n",
        "        Raises:\n",
        "            FileNotFoundError: If the specified image file does not exist.\n",
        "            TypeError: If `image_path` is not a string.\n",
        "            OSError: If there's an issue accessing the image directory or saving results.\n",
        "            Exception: For any other unexpected errors during loading, breaking, or predicting.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Check if the image file exists\n",
        "            if not os.path.exists(image_path):\n",
        "                raise FileNotFoundError(f\"Image not found at: {image_path}\")\n",
        "\n",
        "            # Check if image_path is a string\n",
        "            if not isinstance(image_path, str):\n",
        "                raise TypeError(f\"image_path should be a string, not {type(image_path)}\")\n",
        "\n",
        "            self.image_name = img_name\n",
        "            self.load_model()  # Assuming this method loads your model\n",
        "            image = self.load_image(image_path)  # Assuming this method loads the image\n",
        "            self.break_image(image)  # Break image into smaller windows\n",
        "            preds = self.predict_objects()  # Predict objects in each window\n",
        "            return preds\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            raise e\n",
        "        except TypeError as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            raise e\n",
        "        except OSError as e:\n",
        "            print(f\"Error accessing directory or saving results: {e}\")\n",
        "            raise e\n",
        "        except Exception as e:  # Catch-all for other unexpected errors\n",
        "            print(f\"Unexpected error: {e}\")\n",
        "            raise e\n"
      ],
      "metadata": {
        "id": "_17FbNVhr3Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_outputs_summary(preds):\n",
        "    \"\"\"Creates a summary of object predictions.\n",
        "\n",
        "    This function takes a list of prediction tuples (id, label, confidence) and counts the occurrences of each object label.\n",
        "\n",
        "    Args:\n",
        "        preds (list): A list of prediction tuples (id, label, confidence) from the model.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are object labels and values are the counts of their occurrences.\n",
        "\n",
        "    Raises:\n",
        "        TypeError: If the input `preds` is not a list or if a prediction tuple is not in the expected format.\n",
        "    \"\"\"\n",
        "\n",
        "    # Error handling: Check if input is a list\n",
        "    if not isinstance(preds, list):\n",
        "        raise TypeError(\"Input must be a list of prediction tuples.\")\n",
        "\n",
        "    output_list = {}\n",
        "    for pred in preds:\n",
        "        if pred[1] not in output_list:\n",
        "            output_list[pred[1]] = 1\n",
        "        elif pred[1] in output_list:\n",
        "            output_list[pred[1]] += 1\n",
        "    return output_list\n",
        "\n",
        "\n",
        "def process_outputs_details(preds):\n",
        "    \"\"\"Prints detailed information about object predictions.\n",
        "\n",
        "    This function takes a dictionary of predictions (where keys are window names and values are prediction tuples)\n",
        "    and prints a formatted message for each prediction indicating the object found in the corresponding window.\n",
        "\n",
        "    Args:\n",
        "        preds (dict): A dictionary mapping window names to prediction tuples (id, label, confidence).\n",
        "    \"\"\"\n",
        "    for key, value in preds.items():\n",
        "        print(f\"Found {value[1]} in {key}\")\n"
      ],
      "metadata": {
        "id": "1W9lXQef-45E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/trafiic2.jpg'"
      ],
      "metadata": {
        "id": "pLY_Btzs2jH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = ObjectDetector()\n",
        "final_preds, predections = detector.predict_image(image_path, 'car')"
      ],
      "metadata": {
        "id": "MdMGCKN30e7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25889938-50d0-47bf-ce1a-fbcdb3d12291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created\n",
            "Extracted 25 windows (224*224 images).\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of the output"
      ],
      "metadata": {
        "id": "giCJBJ5z2HZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = process_outputs_summary(predections)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2WhRlWxBs2l",
        "outputId": "ef12af0d-116c-4dbf-f60a-15371a0ff6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cab': 6, 'police_van': 3, 'minivan': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detailed output of each window"
      ],
      "metadata": {
        "id": "fjzEnNM12X79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_outputs_details(final_preds)"
      ],
      "metadata": {
        "id": "GQnWcZ6W2e0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba68694-5d71-43d3-e99e-42b39d94a0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found cab in window_1\n",
            "Found cab in window_2\n",
            "Found police_van in window_4\n",
            "Found cab in window_5\n",
            "Found cab in window_6\n",
            "Found cab in window_10\n",
            "Found police_van in window_12\n",
            "Found police_van in window_13\n",
            "Found cab in window_14\n",
            "Found minivan in window_18\n",
            "Found minivan in window_22\n"
          ]
        }
      ]
    }
  ]
}